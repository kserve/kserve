apiVersion: v1
kind: ConfigMap
metadata:
  name: inferenceservice-config
  namespace: kfserving-system
data:
  predictors: |-
    {
        "tensorflow": {
            "image": "tensorflow/serving",
            "defaultImageVersion": "1.14.0",
            "defaultGpuImageVersion": "1.14.0-gpu",
            "supportedFrameworks": [
              "tensorflow"
            ],
            "multiModelServer": "false"
        },
        "onnx": {
            "image": "mcr.microsoft.com/onnxruntime/server",
            "defaultImageVersion": "v1.0.0",
            "supportedFrameworks": [
              "onnx"
            ],
            "multiModelServer": "false"
        },
        "sklearn": {
          "v1": {
            "image": "gcr.io/kfserving/sklearnserver",
            "defaultImageVersion": "v0.5.0-rc0",
            "supportedFrameworks": [
              "sklearn"
            ],
            "multiModelServer": "ture"
          },
          "v2": {
            "image": "docker.io/seldonio/mlserver",
            "defaultImageVersion": "0.1.2",
            "supportedFrameworks": [
              "sklearn"
            ],
            "multiModelServer": "false"
          }
        },
        "xgboost": {
          "v1": {
            "image": "gcr.io/kfserving/xgbserver",
            "defaultImageVersion": "v0.5.0-rc0",
            "supportedFrameworks": [
              "xgboost"
            ],
            "multiModelServer": "true"
          },
          "v2": {
            "image": "docker.io/seldonio/mlserver",
            "defaultImageVersion": "0.1.2",
            "supportedFrameworks": [
              "xgboost"
            ],
            "multiModelServer": "false"
          }
        },
        "pytorch": {
            "image": "gcr.io/kfserving/pytorchserver",
            "defaultImageVersion": "v0.5.0-rc0",
            "defaultGpuImageVersion": "v0.5.0-rc0-gpu",
            "supportedFrameworks": [
              "pytorch"
            ],
            "multiModelServer": "false"
        },
        "triton": {
            "image": "nvcr.io/nvidia/tritonserver",
            "defaultImageVersion": "20.08-py3",
            "supportedFrameworks": [
              "tensorrt",
              "tensorflow",
              "onnx",
              "pytorch",
              "caffe2"
            ],
            "multiModelServer": "true"
        },
        "pmml": {
            "image": "gcr.io/kfserving/pmmlserver",
            "defaultImageVersion": "v0.5.0-rc0",
            "supportedFrameworks": [
              "pmml"
            ],
            "multiModelServer": "false"
        }
    }
  transformers: |-
    {
    }
  explainers: |-
    {
        "alibi": {
            "image" : "gcr.io/kfserving/alibi-explainer",
            "defaultImageVersion": "v0.5.0-rc0"
        },
        "aix": {
            "image" : "aipipeline/aix-explainer",
            "defaultImageVersion": "0.5.0-rc0"
        }
    }
  storageInitializer: |-
    {
        "image" : "gcr.io/kfserving/storage-initializer:v0.5.0-rc0",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1"
    }
  credentials: |-
    {
       "gcs": {
           "gcsCredentialFileName": "gcloud-application-credentials.json"
       },
       "s3": {
           "s3AccessKeyIDName": "AWS_ACCESS_KEY_ID",
           "s3SecretAccessKeyName": "AWS_SECRET_ACCESS_KEY"
       }
    }
  ingress: |-
    {
        "ingressGateway" : $(ingressGateway)
        "ingressService" : "istio-ingressgateway.istio-system.svc.cluster.local"
    }
  logger: |-
    {
        "image" : "gcr.io/kfserving/logger:v0.5.0-rc0",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1",
        "defaultUrl": "http://default-broker"
    }
  batcher: |-
    {
        "image" : "kfserving/batcher:v0.5.0-rc0",
        "memoryRequest": "1Gi",
        "memoryLimit": "1Gi",
        "cpuRequest": "1",
        "cpuLimit": "1"
    }
  agent: |-
    {
        "image" : "kfserving/agent:v0.5.0-rc0",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1"
    }
