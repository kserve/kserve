apiVersion: v1
kind: ConfigMap
metadata:
  name: inferenceservice-config
  namespace: kfserving-system
data:
  predictors: |-
    {
        "tensorflow": {
            "image": "tensorflow/serving",
            "defaultImageVersion": "1.14.0",
            "defaultGpuImageVersion": "1.14.0-gpu",
            "allowedImageVersions": [
               "1.11.0",
               "1.11.0-gpu",
               "1.12.0",
               "1.12.0-gpu",
               "1.13.0",
               "1.13.0-gpu",
               "1.14.0",
               "1.14.0-gpu"       
            ],
            "supportedFrameworks": [
              "tensorflow"
            ],
            "multiModelServer": "true"
        },
        "onnx": {
            "image": "mcr.microsoft.com/onnxruntime/server",
            "defaultImageVersion": "v0.5.1",
            "allowedImageVersions": [
               "v0.5.1"
            ],
            "supportedFrameworks": [
              "xgboost",
              "pytorch",
              "tensorflow",
              "sklearn",
              "caffe2"
            ],
            "multiModelServer": "false"
        },
        "sklearn": {
            "image": "gcr.io/kfserving/sklearnserver",
            "defaultImageVersion": "v0.3.0",
            "allowedImageVersions": [
               "v0.3.0"
            ],
            "supportedFrameworks": [
              "sklearn"
            ],
            "multiModelServer": "false"
        },
        "xgboost": {
            "image": "gcr.io/kfserving/xgbserver",
            "defaultImageVersion": "v0.3.0",
            "allowedImageVersions": [
               "v0.3.0"
            ],
            "supportedFrameworks": [
              "xgboost"
            ],
            "multiModelServer": "false"
        },
        "pytorch": {
            "image": "gcr.io/kfserving/pytorchserver",
            "defaultImageVersion": "v0.3.0",
            "defaultGpuImageVersion": "v0.3.0-gpu",
            "allowedImageVersions": [
               "v0.3.0",
               "v0.3.0-gpu"
            ],
            "supportedFrameworks": [
              "pytorch"
            ],
            "multiModelServer": "false"
        },
        "triton": {
            "image": "nvcr.io/nvidia/tritonserver",
            "defaultImageVersion": "20.03-py3",
            "allowedImageVersions": [
              "20.03-py3"
            ],
            "supportedFrameworks": [
              "tensorrt",
              "tensorflow",
              "onnx",
              "pytorch",
              "caffe2"
            ],
            "multiModelServer": "true"
        }
    }
  transformers: |-
    {
    }
  explainers: |-
    {
        "alibi": {
            "image" : "gcr.io/kfserving/alibi-explainer",
            "defaultImageVersion": "v0.3.0",
            "allowedImageVersions": [
               "v0.3.0"
            ],
            "supportedModelType": [
              "tabular",
              "text",
              "image"
            ]
        }
    }
  storageInitializer: |-
    {
        "image" : "gcr.io/kfserving/storage-initializer:v0.3.0",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1"
    }
  credentials: |-
    {
       "gcs": {
           "gcsCredentialFileName": "gcloud-application-credentials.json"
       },
       "s3": {
           "s3AccessKeyIDName": "AWS_ACCESS_KEY_ID",
           "s3SecretAccessKeyName": "AWS_SECRET_ACCESS_KEY"
       }
    }
  ingress: |-
    {
        "ingressGateway" : "knative-ingress-gateway.knative-serving",
        "ingressService" : "istio-ingressgateway.istio-system.svc.cluster.local"
    }
  logger: |-
    {
        "image" : "gcr.io/kfserving/logger:v0.3.0",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1"
    }
  batcher: |-
    {
        "image" : "gcr.io/kfserving/batcher:latest",
        "memoryRequest": "1Gi",
        "memoryLimit": "1Gi",
        "cpuRequest": "1",
        "cpuLimit": "1"
    }
