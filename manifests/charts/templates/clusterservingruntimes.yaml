apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-lgbserver
spec:
  supportedModelFormats:
    - name: lightgbm
      version: "2"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.lgbserver.image }}:{{ .Values.kserve.servingruntime.lgbserver.tag }}"
      args:
        - --model_name={{ .Values.kserve.servingruntime.modelNamePlaceholder }}
        - --model_dir=/mnt/models
        - --http_port=8080
        - --nthread=1
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-mlserver
spec:
  supportedModelFormats:
    - name: sklearn
      version: "0"
    - name: xgboost
      version: "1"
    - name: lightgbm
      version: "3"
    - name: mlflow
      version: "1"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.mlserver.image }}:{{ .Values.kserve.servingruntime.mlserver.tag }}"
      env:
        - name: "MLSERVER_MODEL_IMPLEMENTATION"
          value: "{{ .Values.kserve.servingruntime.mlserver.modelClassPlaceholder }}"
        - name: "MLSERVER_HTTP_PORT"
          value: "8080"
        - name: "MLSERVER_GRPC_PORT"
          value: "9000"
        - name: "MODELS_DIR"
          value: "/mnt/models"
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-paddleserver
spec:
  supportedModelFormats:
    - name: paddle
      version: "2"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.paddleserver.image }}:{{ .Values.kserve.servingruntime.paddleserver.tag }}"
      args:
        - --model_name={{ .Values.kserve.servingruntime.modelNamePlaceholder }}
        - --model_dir=/mnt/models
        - --http_port=8080
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-pmmlserver
spec:
  supportedModelFormats:
    - name: pmml
      version: "3"
      autoSelect: true
    - name: pmml
      version: "4"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.pmmlserver.image }}:{{ .Values.kserve.servingruntime.pmmlserver.tag }}"
      args:
        - --model_name={{ .Values.kserve.servingruntime.modelNamePlaceholder }}
        - --model_dir=/mnt/models
        - --http_port=8080
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-sklearnserver
spec:
  supportedModelFormats:
    - name: sklearn
      version: "1"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.sklearnserver.image }}:{{ .Values.kserve.servingruntime.sklearnserver.tag }}"
      args:
        - --model_name={{ .Values.kserve.servingruntime.modelNamePlaceholder }}
        - --model_dir=/mnt/models
        - --http_port=8080
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-tensorflow-serving
spec:
  supportedModelFormats:
    - name: tensorflow
      version: "1"
      autoSelect: true
    - name: tensorflow
      version: "2"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.tensorflow.image }}:{{ .Values.kserve.servingruntime.tensorflow.tag }}"
      command: [/usr/bin/tensorflow_model_server]
      args:
        - --model_name={{ .Values.kserve.servingruntime.modelNamePlaceholder }}
        - --port=9000
        - --rest_api_port=8080
        - --model_base_path=/mnt/models
        - --rest_api_timeout_in_ms=60000
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-torchserve
spec:
  supportedModelFormats:
    - name: pytorch
      version: "1"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.torchserve.image }}:{{ .Values.kserve.servingruntime.torchserve.tag }}"
      args:
        - torchserve
        - --start
        - --model-store=/mnt/models/model-store
        - --ts-config=/mnt/models/config/config.properties
      env:
        - name: "TS_SERVICE_ENVELOPE"
          value: "{{ .Values.kserve.servingruntime.torchserve.serviceEnvelopePlaceholder }}"
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-tritonserver
spec:
  supportedModelFormats:
    - name: tensorrt
      version: "8"
    - name: tensorflow
      version: "1"
    - name: tensorflow
      version: "2"
    - name: onnx
      version: "1"
      autoSelect: true
    - name: pytorch
      version: "1"
    - name: triton
      version: "2"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.tritonserver.image }}:{{ .Values.kserve.servingruntime.tritonserver.tag }}"
      args:
        - tritonserver
        - --model-store=/mnt/models
        - --grpc-port=9000
        - --http-port=8080
        - --allow-grpc=true
        - --allow-http=true
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-xgbserver
spec:
  supportedModelFormats:
    - name: xgboost
      version: "1"
      autoSelect: true
  containers:
    - name: kserve-container
      image: "{{ .Values.kserve.servingruntime.xgbserver.image }}:{{ .Values.kserve.servingruntime.xgbserver.tag }}"
      args:
        - --model_name={{ .Values.kserve.servingruntime.modelNamePlaceholder }}
        - --model_dir=/mnt/models
        - --http_port=8080
        - --nthread=1
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
