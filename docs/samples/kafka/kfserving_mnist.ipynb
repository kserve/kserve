{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample for Inference on kafka image events from Minio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook shows how to use KFServing SDK to create InferenceService with transformer, predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
    "from kubernetes import client\n",
    "\n",
    "from kfserving import KFServingClient\n",
    "from kfserving import constants\n",
    "from kfserving import V1alpha2EndpointSpec\n",
    "from kfserving import V1alpha2PredictorSpec\n",
    "from kfserving import V1alpha2TransformerSpec\n",
    "from kfserving import V1alpha2TensorflowSpec\n",
    "from kfserving import V1alpha2CustomSpec\n",
    "from kfserving import V1alpha2InferenceServiceSpec\n",
    "from kfserving import V1alpha2InferenceService\n",
    "from kubernetes.client import V1Container\n",
    "from kubernetes.client import V1ResourceRequirements\n",
    "import kubernetes.client\n",
    "import os\n",
    "import requests \n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define InferenceService with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add predictor and transformer on the endpoint spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version = constants.KFSERVING_GROUP + '/' + constants.KFSERVING_VERSION\n",
    "default_endpoint_spec = V1alpha2EndpointSpec(\n",
    "                          predictor=V1alpha2PredictorSpec(\n",
    "                            min_replicas=1,\n",
    "                            tensorflow=V1alpha2TensorflowSpec(\n",
    "                              storage_uri='s3://mnist/model-v1/export',\n",
    "                              resources=V1ResourceRequirements(\n",
    "                                  requests={'cpu':'100m','memory':'1Gi'},\n",
    "                                  limits={'cpu':'100m', 'memory':'1Gi'}))),\n",
    "                          transformer=V1alpha2TransformerSpec(\n",
    "                            min_replicas=1,\n",
    "                            custom=V1alpha2CustomSpec(\n",
    "                              container=V1Container(\n",
    "                              image='yuzisun/mnist-transformer:latest',\n",
    "                              name='kfserving-container',\n",
    "                              resources=V1ResourceRequirements(\n",
    "                                  requests={'cpu':'100m','memory':'1Gi'},\n",
    "                                  limits={'cpu':'100m', 'memory':'1Gi'})))))\n",
    "    \n",
    "isvc = V1alpha2InferenceService(api_version=api_version,\n",
    "                          kind=constants.KFSERVING_KIND,\n",
    "                          metadata=client.V1ObjectMeta(\n",
    "                              name='mnist'),\n",
    "                          spec=V1alpha2InferenceServiceSpec(default=default_endpoint_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create InferenceService with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call KFServingClient to create InferenceService."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apiVersion': 'serving.kubeflow.org/v1alpha2',\n",
       " 'kind': 'InferenceService',\n",
       " 'metadata': {'creationTimestamp': '2019-11-19T22:59:10Z',\n",
       "  'generation': 1,\n",
       "  'name': 'mnist',\n",
       "  'namespace': 'default',\n",
       "  'resourceVersion': '162221',\n",
       "  'selfLink': '/apis/serving.kubeflow.org/v1alpha2/namespaces/default/inferenceservices/mnist',\n",
       "  'uid': '87f9afaf-8595-4578-a158-2e8a59f51cbf'},\n",
       " 'spec': {'default': {'predictor': {'minReplicas': 1,\n",
       "    'tensorflow': {'resources': {'limits': {'cpu': '100m', 'memory': '1Gi'},\n",
       "      'requests': {'cpu': '100m', 'memory': '1Gi'}},\n",
       "     'runtimeVersion': '1.14.0',\n",
       "     'storageUri': 's3://mnist/model-v1'}},\n",
       "   'transformer': {'custom': {'container': {'image': 'yuzisun/mnist-transformer:latest',\n",
       "      'name': 'kfserving-container',\n",
       "      'resources': {'limits': {'cpu': '100m', 'memory': '1Gi'},\n",
       "       'requests': {'cpu': '100m', 'memory': '1Gi'}}}},\n",
       "    'minReplicas': 1}}},\n",
       " 'status': {}}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFServing = KFServingClient()\n",
    "KFServing.create(isvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the InferenceService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 READY      DEFAULT_TRAFFIC CANARY_TRAFFIC  URL                                               \n",
      "mnist                False                                                                                        \n",
      "mnist                False                                                                                        \n",
      "mnist                False                                                                                        \n",
      "mnist                True       100                             http://mnist.default.example.com/v1/models/mnist  \n"
     ]
    }
   ],
   "source": [
    "KFServing.get('mnist', watch=True, timeout_seconds=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = kubernetes.client.CoreV1Api(kubernetes.client.ApiClient())\n",
    "service = api_instance.read_namespaced_service(\"istio-ingressgateway\", \"istio-system\", exact='true')\n",
    "#cluster_ip = \"service.status.load_balancer.ingress[0].ip\"\n",
    "cluster_ip = \"127.0.0.1:8080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://\" + cluster_ip + \"/v1/models/mnist/metadata\"\n",
    "headers = { 'Host': 'mnist-predictor-default.default.example.com' }\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the InferenceService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFServing.delete('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
