apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: "torchserve-bloom-560m"
spec:
  predictor:
    pytorch:
      storageUri: pvc://model-cache
      resources:
          limits:
            cpu: 4
            memory: 16Gi
            nvidia.com/gpu: 1
  nodeName: ip-xxx-xxx-xxx-xxx.us-west-2.compute.internal
