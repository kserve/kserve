apiVersion: "serving.kubeflow.org/v1beta1"
kind: "InferenceService"
metadata:
  name: "my-model"
spec:
  predictor:
    tensorflow:
      resources:
        limits:
          cpu: 100m
          memory: "100Mi"
        requests:
          cpu: 100m
          memory: "100Mi"    
      storageUri: "gs://kfserving-samples/models/tensorflow/flowers-2"
