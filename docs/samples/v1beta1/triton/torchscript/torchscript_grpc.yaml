apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "torchscript-cifar"
spec:
  predictor:
    triton:
      storageUri: "gs://kfserving-examples/models/torchscript"
      runtimeVersion: 20.10-py3
      ports:
        - name: h2c
          protocol: TCP
          containerPort: 9000
      env:
        - name: OMP_NUM_THREADS
          value: "1"
