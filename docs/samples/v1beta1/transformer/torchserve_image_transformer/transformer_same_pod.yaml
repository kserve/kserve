apiVersion: serving.kubeflow.org/v1beta1
kind: InferenceService
metadata:
  name: torchserve-transformer
spec:
  predictor:
    containers:
    - image: kfserving/torchserve-image-transformer:latest
      name: transformer-container
      args:
        - --model_name
        - mnist
        - --http_port
        - "8000"
        - --predictor_host
        - localhost:8080
      ports:
        - containerPort: 8000
          protocol: TCP
      env:
        - name: STORAGE_URI
          value: gs://kfserving-examples/models/torchserve/image_classifier
    - image: kfserving/torchserve-kfs:0.3.0
      name: kfserving-container
      args:
        - torchserve
        - --start
        - --model-store=/mnt/models/model-store
        - --ts-config=/mnt/models/config/config.properties
      env:
        - name: STORAGE_URI 
          value: gs://kfserving-examples/models/torchserve/image_classifier
