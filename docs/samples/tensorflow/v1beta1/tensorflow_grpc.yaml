apiVersion: "serving.kubeflow.org/v1beta1"
kind: "InferenceService"
metadata:
  name: "flowers-grpc"
spec:
  predictor:
    tensorflow:
      runtimeVersion: 2.0.0
      storageUri: "gs://kfserving-samples/models/tensorflow/flowers"
      ports:
        - name: h2c
          containerPort: 9000

