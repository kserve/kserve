apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "fluid-bloom"
  labels:
    serverless.fluid.io/inject: "true"
spec:
  predictor:
    terminationGracePeriodSeconds: 60
    timeout: 600
    minReplicas: 0
    nodeSelector:
      node.kubernetes.io/instance-type: m5.4xlarge
    containers:
      - name: kserve-container
        image: lizzzcai/kserve-fluid:bloom-gpu-v1
        # # below are for running bloom-7b1 using cpu
        # resources:
        #   limits:
        #     cpu: "12"
        #     memory: 48Gi
        #   requests:
        #     cpu: "12"
        #     memory: 48Gi
        env:
          - name: STORAGE_URI
            # please update it accordingly
            value: "pvc://s3-data/bloom-560m"
            # value: "pvc://s3-data/bloom-7b1"
          - name: MODEL_NAME
            value: "bloom"
            # set to "True" if you are using GPU, update the resources as well
          - name: GPU_ENABLED
            value: "False"