apiVersion: serving.kserve.io/v1alpha1
kind: LLMInferenceService
metadata:
  name: deepseek-v2-lite-chat
  annotations:
    leaderworkerset.sigs.k8s.io/subgroup-exclusive-topology: kubernetes.io/hostname
spec:
  model:
    uri: hf://deepseek-ai/DeepSeek-V2-Lite-Chat
    name: deepseek-ai/DeepSeek-V2-Lite-Chat
  replicas: 2
  parallelism:
    data: 8
    dataLocal: 8
    expert: true
    tensor: 1
  router:
    scheduler: { }
    route: { }
    gateway: { }
  prefill:
    parallelism:
      data: 1
      dataLocal: 8
      expert: true
      tensor: 1
    template:
      containers:
        - name: main
          env:
            - name: VLLM_LOGGING_LEVEL
              value: INFO
            - name: TRITON_LIBCUDA_PATH
              value: /usr/lib64
            - name: HF_HUB_DISABLE_XET
              value: "1"
            - name: VLLM_SKIP_P2P_CHECK
              value: "1"
            - name: VLLM_RANDOMIZE_DP_DUMMY_INPUTS
              value: "1"
            # Disabled because of https://github.com/vllm-project/vllm/pull/21517 and llm-d 0.2 doesn't include the fix.
            - name: VLLM_USE_DEEP_GEMM
              value: "0"
            - name: VLLM_ALL2ALL_BACKEND
              value: deepep_high_throughput
            - name: NVIDIA_GDRCOPY
              value: enabled
            - name: NVSHMEM_DEBUG
              value: INFO
            - name: NVSHMEM_REMOTE_TRANSPORT
              value: ucx  # Use UCX for RoCE, use `ibgda` for IB
            - name: NVSHMEM_BOOTSTRAP_UID_SOCK_IFNAME
              value: eth0
            - name: GLOO_SOCKET_IFNAME
              value: eth0
            - name: NCCL_SOCKET_IFNAME
              value: eth0
            # - name: NCCL_IB_HCA # IB-specific
            #   value: ibp
            # - name: NVSHMEM_IB_ENABLE_IBGDA # IB-specific
            #   value: "true"
            - name: HF_HUB_CACHE
              value: /huggingface-cache
            - name: VLLM_NIXL_SIDE_CHANNEL_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: VLLM_ADDITIONAL_ARGS
              value: "--kv_transfer_config '{\"kv_connector\":\"NixlConnector\",\"kv_role\":\"kv_both\"}'"
            - name: UCX_NET_DEVICES
              value: "eth0"
            - name: UCX_IB_GID_INDEX
              value: "auto"
            - name: UCX_PROTO_INFO
              value: "y"
            - name: UCX_LOG_LEVEL
              value: "INFO"
          resources:
            limits:
              cpu: 16
              ephemeral-storage: 64Gi
              memory: 512Gi
              nvidia.com/gpu: "8"
              rdma/roce_gdr: 1 # rdma/ib for IB
            requests:
              cpu: 8
              ephemeral-storage: 32Gi
              memory: 256Gi
              nvidia.com/gpu: "8"
              rdma/roce_gdr: 1 # rdma/ib for IB
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
              scheme: HTTPS
            initialDelaySeconds: 400
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 3
    worker:
      containers:
        - name: main
          env:
            - name: VLLM_LOGGING_LEVEL
              value: INFO
            - name: TRITON_LIBCUDA_PATH
              value: /usr/lib64
            - name: HF_HUB_DISABLE_XET
              value: "1"
            - name: VLLM_SKIP_P2P_CHECK
              value: "1"
            - name: VLLM_RANDOMIZE_DP_DUMMY_INPUTS
              value: "1"
            # Disabled because of https://github.com/vllm-project/vllm/pull/21517 and llm-d 0.2 doesn't include the fix.
            - name: VLLM_USE_DEEP_GEMM
              value: "0"
            - name: VLLM_ALL2ALL_BACKEND
              value: deepep_high_throughput
            - name: NVIDIA_GDRCOPY
              value: enabled
            - name: NVSHMEM_DEBUG
              value: INFO
            - name: NVSHMEM_REMOTE_TRANSPORT
              value: ucx  # Use UCX for RoCE, use `ibgda` for IB
            - name: NVSHMEM_BOOTSTRAP_UID_SOCK_IFNAME
              value: eth0
            - name: GLOO_SOCKET_IFNAME
              value: eth0
            - name: NCCL_SOCKET_IFNAME
              value: eth0
            # - name: NCCL_IB_HCA # IB-specific
            #   value: ibp
            # - name: NVSHMEM_IB_ENABLE_IBGDA # IB-specific
            #   value: "true"
            - name: HF_HUB_CACHE
              value: /huggingface-cache
            - name: VLLM_NIXL_SIDE_CHANNEL_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: VLLM_ADDITIONAL_ARGS
              value: "--kv_transfer_config '{\"kv_connector\":\"NixlConnector\",\"kv_role\":\"kv_both\"}'"
            - name: UCX_NET_DEVICES
              value: "eth0"
            - name: UCX_IB_GID_INDEX
              value: "auto"
            - name: UCX_PROTO_INFO
              value: "y"
            - name: UCX_LOG_LEVEL
              value: "INFO"
          resources:
            limits:
              cpu: 16
              ephemeral-storage: 64Gi
              memory: 512Gi
              nvidia.com/gpu: "8"
              rdma/roce_gdr: 1 # rdma/ib for IB
            requests:
              cpu: 8
              ephemeral-storage: 32Gi
              memory: 256Gi
              nvidia.com/gpu: "8"
              rdma/roce_gdr: 1 # rdma/ib for IB
  template:
    containers:
      - name: main
        env:
          - name: VLLM_LOGGING_LEVEL
            value: DEBUG
          - name: TRITON_LIBCUDA_PATH
            value: /usr/lib64
          - name: HF_HUB_DISABLE_XET
            value: "1"
          - name: VLLM_SKIP_P2P_CHECK
            value: "1"
          - name: VLLM_RANDOMIZE_DP_DUMMY_INPUTS
            value: "1"
          # Disabled because of https://github.com/vllm-project/vllm/pull/21517 and llm-d 0.2 doesn't include the fix.
          - name: VLLM_USE_DEEP_GEMM
            value: "0"
          - name: VLLM_ALL2ALL_BACKEND
            value: deepep_high_throughput
          - name: NVIDIA_GDRCOPY
            value: enabled
          - name: NVSHMEM_DEBUG
            value: INFO
          - name: NVSHMEM_REMOTE_TRANSPORT
            value: ucx  # Use UCX for RoCE, use `ibgda` for IB
          - name: NVSHMEM_BOOTSTRAP_UID_SOCK_IFNAME
            value: eth0
          - name: GLOO_SOCKET_IFNAME
            value: eth0
          - name: NCCL_SOCKET_IFNAME
            value: eth0
          # - name: NCCL_IB_HCA # IB-specific
          #   value: ibp
          # - name: NVSHMEM_IB_ENABLE_IBGDA # IB-specific
          #   value: "true"
          - name: HF_HUB_CACHE
            value: /huggingface-cache
          - name: VLLM_NIXL_SIDE_CHANNEL_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: VLLM_ADDITIONAL_ARGS
            value: "--kv_transfer_config '{\"kv_connector\":\"NixlConnector\",\"kv_role\":\"kv_both\"}'"
          - name: UCX_NET_DEVICES
            value: "eth0"
          - name: UCX_IB_GID_INDEX
            value: "auto"
          - name: UCX_PROTO_INFO
            value: "y"
          - name: UCX_LOG_LEVEL
            value: "INFO"
        resources:
          limits:
            cpu: 16
            ephemeral-storage: 64Gi
            memory: 512Gi
            nvidia.com/gpu: "8"
            rdma/roce_gdr: 1 # rdma/ib for IB
          requests:
            cpu: 8
            ephemeral-storage: 32Gi
            memory: 256Gi
            nvidia.com/gpu: "8"
            rdma/roce_gdr: 1 # rdma/ib for IB
        livenessProbe:
          httpGet:
            path: /health
            port: 8001
            scheme: HTTPS
          initialDelaySeconds: 400
          periodSeconds: 10
          timeoutSeconds: 10
          failureThreshold: 3
  worker:
    containers:
      - name: main
        env:
          - name: VLLM_LOGGING_LEVEL
            value: DEBUG
          - name: TRITON_LIBCUDA_PATH
            value: /usr/lib64
          - name: HF_HUB_DISABLE_XET
            value: "1"
          - name: VLLM_SKIP_P2P_CHECK
            value: "1"
          - name: VLLM_RANDOMIZE_DP_DUMMY_INPUTS
            value: "1"
          # Disabled because of https://github.com/vllm-project/vllm/pull/21517 and llm-d 0.2 doesn't include the fix.
          - name: VLLM_USE_DEEP_GEMM
            value: "0"
          - name: VLLM_ALL2ALL_BACKEND
            value: deepep_high_throughput
          - name: NVIDIA_GDRCOPY
            value: enabled
          - name: NVSHMEM_DEBUG
            value: INFO
          - name: NVSHMEM_REMOTE_TRANSPORT
            value: ucx  # Use UCX for RoCE, use `ibgda` for IB
          - name: NVSHMEM_BOOTSTRAP_UID_SOCK_IFNAME
            value: eth0
          - name: GLOO_SOCKET_IFNAME
            value: eth0
          - name: NCCL_SOCKET_IFNAME
            value: eth0
          # - name: NCCL_IB_HCA # IB-specific
          #   value: ibp
          # - name: NVSHMEM_IB_ENABLE_IBGDA # IB-specific
          #   value: "true"
          - name: HF_HUB_CACHE
            value: /huggingface-cache
          - name: VLLM_NIXL_SIDE_CHANNEL_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: VLLM_ADDITIONAL_ARGS
            value: "--kv_transfer_config '{\"kv_connector\":\"NixlConnector\",\"kv_role\":\"kv_both\"}'"
          - name: UCX_NET_DEVICES
            value: "eth0"
          - name: UCX_IB_GID_INDEX
            value: "auto"
          - name: UCX_PROTO_INFO
            value: "y"
          - name: UCX_LOG_LEVEL
            value: "INFO"
        resources:
          limits:
            cpu: 16
            ephemeral-storage: 64Gi
            memory: 512Gi
            nvidia.com/gpu: "8"
            rdma/roce_gdr: 1 # rdma/ib for IB
          requests:
            cpu: 8
            ephemeral-storage: 32Gi
            memory: 256Gi
            nvidia.com/gpu: "8"
            rdma/roce_gdr: 1 # rdma/ib for IB
