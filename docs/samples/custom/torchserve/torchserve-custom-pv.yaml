apiVersion: "serving.kubeflow.org/v1beta1"
kind: "InferenceService"
metadata:
  name: "torchserve-custom-pv"
spec:
  predictor:
    containers:
      - image: {username}/torchserve:latest
        name: kfserving-container
        env:
          - name: STORAGE_URI
            value: "pvc://model-pv-claim" # The storage mounts to /mnt/models
