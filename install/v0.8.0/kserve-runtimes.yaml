apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-lgbserver
spec:
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    - --nthread=1
    image: kserve/lgbserver:v0.8.0
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - autoSelect: true
    name: lightgbm
    version: "2"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-mlserver
spec:
  containers:
  - env:
    - name: MLSERVER_MODEL_IMPLEMENTATION
      value: '{{.Labels.modelClass}}'
    - name: MLSERVER_HTTP_PORT
      value: "8080"
    - name: MLSERVER_GRPC_PORT
      value: "9000"
    - name: MODELS_DIR
      value: /mnt/models
    image: docker.io/seldonio/mlserver:0.5.3
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - name: sklearn
    version: "0"
  - name: xgboost
    version: "1"
  - name: lightgbm
    version: "3"
  - autoSelect: true
    name: mlflow
    version: "1"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-paddleserver
spec:
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    image: kserve/paddleserver:v0.8.0
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - autoSelect: true
    name: paddle
    version: "2"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-pmmlserver
spec:
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    image: kserve/pmmlserver:v0.8.0
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - autoSelect: true
    name: pmml
    version: "3"
  - autoSelect: true
    name: pmml
    version: "4"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-sklearnserver
spec:
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    image: kserve/sklearnserver:v0.8.0
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - autoSelect: true
    name: sklearn
    version: "1"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-tensorflow-serving
spec:
  containers:
  - args:
    - --model_name={{.Name}}
    - --port=9000
    - --rest_api_port=8080
    - --model_base_path=/mnt/models
    - --rest_api_timeout_in_ms=60000
    command:
    - /usr/bin/tensorflow_model_server
    image: tensorflow/serving:2.6.2
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - autoSelect: true
    name: tensorflow
    version: "1"
  - autoSelect: true
    name: tensorflow
    version: "2"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-torchserve
spec:
  containers:
  - args:
    - torchserve
    - --start
    - --model-store=/mnt/models/model-store
    - --ts-config=/mnt/models/config/config.properties
    env:
    - name: TS_SERVICE_ENVELOPE
      value: '{{.Labels.serviceEnvelope}}'
    image: kserve/torchserve-kfs:0.5.3
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - autoSelect: true
    name: pytorch
    version: "1"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-tritonserver
spec:
  containers:
  - args:
    - tritonserver
    - --model-store=/mnt/models
    - --grpc-port=9000
    - --http-port=8080
    - --allow-grpc=true
    - --allow-http=true
    image: nvcr.io/nvidia/tritonserver:21.09-py3
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - name: tensorrt
    version: "8"
  - name: tensorflow
    version: "1"
  - name: tensorflow
    version: "2"
  - autoSelect: true
    name: onnx
    version: "1"
  - name: pytorch
    version: "1"
  - autoSelect: true
    name: triton
    version: "2"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-xgbserver
spec:
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    - --nthread=1
    image: kserve/xgbserver:v0.8.0
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
  supportedModelFormats:
  - autoSelect: true
    name: xgboost
    version: "1"
