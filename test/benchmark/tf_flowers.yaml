apiVersion: "serving.kserve.io/v1alpha2"
kind: "InferenceService"
metadata:
  name: "flowers-sample"
spec:
  default:
    predictor:
      parallelism: 1 #CC=1
      tensorflow:
        storageUri: "gs://kfserving-samples/models/tensorflow/flowers"
        resources:
          requests:
            cpu: "4"
            memory: "2Gi"
          limits:
            cpu: "4"
            memory: "2Gi"
