# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: inference.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()

DESCRIPTOR = _descriptor.FileDescriptor(
    name='inference.proto',
    package='org.pytorch.serve.grpc.inference',
    syntax='proto3',
    serialized_options=b'P\001',
    create_key=_descriptor._internal_create_key,
    serialized_pb=b'\n\x0finference.proto\x12 org.pytorch.serve.grpc.inference\x1a\x1bgoogle/protobuf/empty.proto\"\xbd\x01\n\x12PredictionsRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x15\n\rmodel_version\x18\x02 \x01(\t\x12N\n\x05input\x18\x03 \x03(\x0b\x32?.org.pytorch.serve.grpc.inference.PredictionsRequest.InputEntry\x1a,\n\nInputEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x0c:\x02\x38\x01\"(\n\x12PredictionResponse\x12\x12\n\nprediction\x18\x01 \x01(\x0c\"*\n\x18TorchServeHealthResponse\x12\x0e\n\x06health\x18\x01 \x01(\t2\xf1\x01\n\x14InferenceAPIsService\x12\\\n\x04Ping\x12\x16.google.protobuf.Empty\x1a:.org.pytorch.serve.grpc.inference.TorchServeHealthResponse\"\x00\x12{\n\x0bPredictions\x12\x34.org.pytorch.serve.grpc.inference.PredictionsRequest\x1a\x34.org.pytorch.serve.grpc.inference.PredictionResponse\"\x00\x42\x02P\x01\x62\x06proto3',  # noqa: E501
    dependencies=[
        google_dot_protobuf_dot_empty__pb2.DESCRIPTOR,
    ])

_PREDICTIONSREQUEST_INPUTENTRY = _descriptor.Descriptor(
    name='InputEntry',
    full_name='org.pytorch.serve.grpc.inference.PredictionsRequest.InputEntry',
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(name='key',
                                    full_name='org.pytorch.serve.grpc.inference.PredictionsRequest.InputEntry.key',
                                    index=0,
                                    number=1,
                                    type=9,
                                    cpp_type=9,
                                    label=1,
                                    has_default_value=False,
                                    default_value=b"".decode('utf-8'),
                                    message_type=None,
                                    enum_type=None,
                                    containing_type=None,
                                    is_extension=False,
                                    extension_scope=None,
                                    serialized_options=None,
                                    file=DESCRIPTOR,
                                    create_key=_descriptor._internal_create_key),
        _descriptor.FieldDescriptor(name='value',
                                    full_name='org.pytorch.serve.grpc.inference.PredictionsRequest.InputEntry.value',
                                    index=1,
                                    number=2,
                                    type=12,
                                    cpp_type=9,
                                    label=1,
                                    has_default_value=False,
                                    default_value=b"",
                                    message_type=None,
                                    enum_type=None,
                                    containing_type=None,
                                    is_extension=False,
                                    extension_scope=None,
                                    serialized_options=None,
                                    file=DESCRIPTOR,
                                    create_key=_descriptor._internal_create_key),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=b'8\001',
    is_extendable=False,
    syntax='proto3',
    extension_ranges=[],
    oneofs=[],
    serialized_start=228,
    serialized_end=272,
)

_PREDICTIONSREQUEST = _descriptor.Descriptor(
    name='PredictionsRequest',
    full_name='org.pytorch.serve.grpc.inference.PredictionsRequest',
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(name='model_name',
                                    full_name='org.pytorch.serve.grpc.inference.PredictionsRequest.model_name',
                                    index=0,
                                    number=1,
                                    type=9,
                                    cpp_type=9,
                                    label=1,
                                    has_default_value=False,
                                    default_value=b"".decode('utf-8'),
                                    message_type=None,
                                    enum_type=None,
                                    containing_type=None,
                                    is_extension=False,
                                    extension_scope=None,
                                    serialized_options=None,
                                    file=DESCRIPTOR,
                                    create_key=_descriptor._internal_create_key),
        _descriptor.FieldDescriptor(name='model_version',
                                    full_name='org.pytorch.serve.grpc.inference.PredictionsRequest.model_version',
                                    index=1,
                                    number=2,
                                    type=9,
                                    cpp_type=9,
                                    label=1,
                                    has_default_value=False,
                                    default_value=b"".decode('utf-8'),
                                    message_type=None,
                                    enum_type=None,
                                    containing_type=None,
                                    is_extension=False,
                                    extension_scope=None,
                                    serialized_options=None,
                                    file=DESCRIPTOR,
                                    create_key=_descriptor._internal_create_key),
        _descriptor.FieldDescriptor(name='input',
                                    full_name='org.pytorch.serve.grpc.inference.PredictionsRequest.input',
                                    index=2,
                                    number=3,
                                    type=11,
                                    cpp_type=10,
                                    label=3,
                                    has_default_value=False,
                                    default_value=[],
                                    message_type=None,
                                    enum_type=None,
                                    containing_type=None,
                                    is_extension=False,
                                    extension_scope=None,
                                    serialized_options=None,
                                    file=DESCRIPTOR,
                                    create_key=_descriptor._internal_create_key),
    ],
    extensions=[],
    nested_types=[
        _PREDICTIONSREQUEST_INPUTENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax='proto3',
    extension_ranges=[],
    oneofs=[],
    serialized_start=83,
    serialized_end=272,
)

_PREDICTIONRESPONSE = _descriptor.Descriptor(
    name='PredictionResponse',
    full_name='org.pytorch.serve.grpc.inference.PredictionResponse',
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(name='prediction',
                                    full_name='org.pytorch.serve.grpc.inference.PredictionResponse.prediction',
                                    index=0,
                                    number=1,
                                    type=12,
                                    cpp_type=9,
                                    label=1,
                                    has_default_value=False,
                                    default_value=b"",
                                    message_type=None,
                                    enum_type=None,
                                    containing_type=None,
                                    is_extension=False,
                                    extension_scope=None,
                                    serialized_options=None,
                                    file=DESCRIPTOR,
                                    create_key=_descriptor._internal_create_key),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax='proto3',
    extension_ranges=[],
    oneofs=[],
    serialized_start=274,
    serialized_end=314,
)

_TORCHSERVEHEALTHRESPONSE = _descriptor.Descriptor(
    name='TorchServeHealthResponse',
    full_name='org.pytorch.serve.grpc.inference.TorchServeHealthResponse',
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(name='health',
                                    full_name='org.pytorch.serve.grpc.inference.TorchServeHealthResponse.health',
                                    index=0,
                                    number=1,
                                    type=9,
                                    cpp_type=9,
                                    label=1,
                                    has_default_value=False,
                                    default_value=b"".decode('utf-8'),
                                    message_type=None,
                                    enum_type=None,
                                    containing_type=None,
                                    is_extension=False,
                                    extension_scope=None,
                                    serialized_options=None,
                                    file=DESCRIPTOR,
                                    create_key=_descriptor._internal_create_key),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax='proto3',
    extension_ranges=[],
    oneofs=[],
    serialized_start=316,
    serialized_end=358,
)

_PREDICTIONSREQUEST_INPUTENTRY.containing_type = _PREDICTIONSREQUEST
_PREDICTIONSREQUEST.fields_by_name['input'].message_type = _PREDICTIONSREQUEST_INPUTENTRY
DESCRIPTOR.message_types_by_name['PredictionsRequest'] = _PREDICTIONSREQUEST
DESCRIPTOR.message_types_by_name['PredictionResponse'] = _PREDICTIONRESPONSE
DESCRIPTOR.message_types_by_name['TorchServeHealthResponse'] = _TORCHSERVEHEALTHRESPONSE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

PredictionsRequest = _reflection.GeneratedProtocolMessageType(
    'PredictionsRequest',
    (_message.Message,),
    {
        'InputEntry':
            _reflection.GeneratedProtocolMessageType(
                'InputEntry',
                (_message.Message,),
                {
                    'DESCRIPTOR': _PREDICTIONSREQUEST_INPUTENTRY,
                    '__module__': 'inference_pb2'
                    # @@protoc_insertion_point(class_scope:org.pytorch.serve.grpc.inference.PredictionsRequest.InputEntry)
                }),
        'DESCRIPTOR':
            _PREDICTIONSREQUEST,
        '__module__':
            'inference_pb2'
        # @@protoc_insertion_point(class_scope:org.pytorch.serve.grpc.inference.PredictionsRequest)
    })
_sym_db.RegisterMessage(PredictionsRequest)
_sym_db.RegisterMessage(PredictionsRequest.InputEntry)

PredictionResponse = _reflection.GeneratedProtocolMessageType(
    'PredictionResponse',
    (_message.Message,),
    {
        'DESCRIPTOR': _PREDICTIONRESPONSE,
        '__module__': 'inference_pb2'
        # @@protoc_insertion_point(class_scope:org.pytorch.serve.grpc.inference.PredictionResponse)
    })
_sym_db.RegisterMessage(PredictionResponse)

TorchServeHealthResponse = _reflection.GeneratedProtocolMessageType(
    'TorchServeHealthResponse',
    (_message.Message,),
    {
        'DESCRIPTOR': _TORCHSERVEHEALTHRESPONSE,
        '__module__': 'inference_pb2'
        # @@protoc_insertion_point(class_scope:org.pytorch.serve.grpc.inference.TorchServeHealthResponse)
    })
_sym_db.RegisterMessage(TorchServeHealthResponse)

DESCRIPTOR._options = None
_PREDICTIONSREQUEST_INPUTENTRY._options = None

_INFERENCEAPISSERVICE = _descriptor.ServiceDescriptor(
    name='InferenceAPIsService',
    full_name='org.pytorch.serve.grpc.inference.InferenceAPIsService',
    file=DESCRIPTOR,
    index=0,
    serialized_options=None,
    create_key=_descriptor._internal_create_key,
    serialized_start=361,
    serialized_end=602,
    methods=[
        _descriptor.MethodDescriptor(
            name='Ping',
            full_name='org.pytorch.serve.grpc.inference.InferenceAPIsService.Ping',
            index=0,
            containing_service=None,
            input_type=google_dot_protobuf_dot_empty__pb2._EMPTY,
            output_type=_TORCHSERVEHEALTHRESPONSE,
            serialized_options=None,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.MethodDescriptor(
            name='Predictions',
            full_name='org.pytorch.serve.grpc.inference.InferenceAPIsService.Predictions',
            index=1,
            containing_service=None,
            input_type=_PREDICTIONSREQUEST,
            output_type=_PREDICTIONRESPONSE,
            serialized_options=None,
            create_key=_descriptor._internal_create_key,
        ),
    ])
_sym_db.RegisterServiceDescriptor(_INFERENCEAPISSERVICE)

DESCRIPTOR.services_by_name['InferenceAPIsService'] = _INFERENCEAPISSERVICE

# @@protoc_insertion_point(module_scope)
