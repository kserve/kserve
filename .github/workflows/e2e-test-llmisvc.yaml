name: LLMInferenceService E2E Tests

on:
  pull_request:
    branches: [master, release*, feature-llmd-*]
    paths:
      - "**"
      - "!.github/**"
      - "!docs/**"
      - "!**.md"
      - ".github/workflows/e2e-test-llmisvc.yml"
  workflow_dispatch:

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  DOCKER_IMAGES_PATH: "/mnt/docker-images"
  DOCKER_REPO: "kserve"
  # artifact prefixes for bulk download
  PREDICTOR_ARTIFACT_PREFIX: "pred"
  EXPLAINER_ARTIFACT_PREFIX: "exp"
  TRANSFORMER_ARTIFACT_PREFIX: "trans"
  GRAPH_ARTIFACT_PREFIX: "graph"
  BASE_ARTIFACT_PREFIX: "base"
  # Controller images
  CONTROLLER_IMG: "kserve-controller"
  LLMISVC_CONTROLLER_IMG: "llmisvc-controller"
  LOCALMODEL_CONTROLLER_IMG: "kserve-localmodel-controller"
  LOCALMODEL_AGENT_IMG: "kserve-localmodelnode-agent"
  STORAGE_INIT_IMG: "storage-initializer"
  AGENT_IMG: "agent"
  ROUTER_IMG: "router"
  # Predictor runtime server images
  SKLEARN_IMG: "sklearnserver"
  XGB_IMG: "xgbserver"
  LGB_IMG: "lgbserver"
  PMML_IMG: "pmmlserver"
  PADDLE_IMG: "paddleserver"
  CUSTOM_MODEL_GRPC_IMG: "custom-model-grpc"
  CUSTOM_MODEL_GRPC_IMG_TAG: "kserve/custom-model-grpc:${{ github.sha }}"
  HUGGINGFACE_IMG: "huggingfaceserver"
  # Explainer images
  ART_IMG: "art-explainer"
  # Transformer images
  IMAGE_TRANSFORMER_IMG: "image-transformer"
  IMAGE_TRANSFORMER_IMG_TAG: "kserve/image-transformer:${{ github.sha }}"
  CUSTOM_TRANSFORMER_GRPC_IMG: "custom-image-transformer-grpc"
  # Graph images
  SUCCESS_200_ISVC_IMG: "success-200-isvc"
  ERROR_404_ISVC_IMG: "error-404-isvc"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test-llmisvc:
    runs-on: ubuntu-22.04
    needs: [kserve-image-build]
    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Free-up disk space
        uses: ./.github/actions/free-up-disk-space

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Setup Minikube
        uses: ./.github/actions/minikube-setup
        with:
          addons: "metallb"

      - name: KServe dependency setup
        uses: ./.github/actions/kserve-dep-setup
        with:
          network-layer: "istio-gatewayapi-ext"
          enable-lws: "true"

      - name: Download base images
        uses: ./.github/actions/base-download

      - name: Setup UV
        run: ./test/scripts/gh-actions/setup-uv.sh

      - name: Install KServe
        run: |
          ./test/scripts/gh-actions/setup-kserve.sh "raw" "istio-gatewayapi-ext"

      - name: Setup LLM Controller
        run: |
          # Deploy the dedicated LLM controller
          echo "ðŸš€ Setting up dedicated LLM controller..."

          # Apply LLM controller RBAC
          kubectl apply -f config/rbac/llmisvc/role.yaml
          kubectl create clusterrolebinding llmisvc-manager-rolebinding \
            --clusterrole=llmisvc-manager-role \
            --serviceaccount=kserve:kserve-controller-manager \
            --dry-run=client -o yaml | kubectl apply -f -

          # Create LLM controller deployment
          kubectl apply -f - <<EOF
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            labels:
              app.kubernetes.io/name: llm-isvc-controller-manager
              control-plane: llm-isvc-controller-manager
            name: llm-isvc-controller-manager
            namespace: kserve
          spec:
            replicas: 1
            selector:
              matchLabels:
                control-plane: llm-isvc-controller-manager
            template:
              metadata:
                annotations:
                  kubectl.kubernetes.io/default-container: manager
                labels:
                  control-plane: llm-isvc-controller-manager
              spec:
                containers:
                - args:
                  - --metrics-addr=127.0.0.1:8080
                  - --leader-elect
                  env:
                  - name: POD_NAMESPACE
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.namespace
                  image: ${{ env.DOCKER_REPO }}/${{ env.LLMISVC_CONTROLLER_IMG }}:${{ github.sha }}
                  name: manager
                  ports:
                  - containerPort: 9443
                    name: webhook-server
                    protocol: TCP
                  resources:
                    limits:
                      cpu: 500m
                      memory: 128Mi
                    requests:
                      cpu: 10m
                      memory: 64Mi
                  securityContext:
                    allowPrivilegeEscalation: false
                    capabilities:
                      drop:
                      - ALL
                  volumeMounts:
                  - mountPath: /tmp/k8s-webhook-server/serving-certs
                    name: cert
                    readOnly: true
                securityContext:
                  runAsNonRoot: true
                serviceAccountName: kserve-controller-manager
                terminationGracePeriodSeconds: 10
                volumes:
                - name: cert
                  secret:
                    defaultMode: 420
                    secretName: kserve-webhook-server-cert
          EOF

          # Create LLM webhook service
          kubectl apply -f - <<EOF
          apiVersion: v1
          kind: Service
          metadata:
            name: llm-isvc-webhook-server-service
            namespace: kserve
          spec:
            ports:
            - name: webhook-server
              port: 443
              targetPort: 9443
            selector:
              control-plane: llm-isvc-controller-manager
          EOF

          # Update webhook configurations to point to LLM controller
          kubectl patch validatingwebhookconfiguration llminferenceserviceconfig.serving.kserve.io --type='json' -p='[{
            "op": "replace",
            "path": "/webhooks/0/clientConfig/service/name",
            "value": "llm-isvc-webhook-server-service"
          }]'

          kubectl patch validatingwebhookconfiguration llminferenceservice.serving.kserve.io --type='json' -p='[{
            "op": "replace", 
            "path": "/webhooks/0/clientConfig/service/name",
            "value": "llm-isvc-webhook-server-service"
          }]'

          echo "âœ… LLM controller setup complete!"

      - name: Run E2E tests
        timeout-minutes: 30
        run: |
          # Run only CPU tests for now using pytest markers (cluster_)
          # Available GPU vendors: amd, nvidia, intel
          ./test/scripts/gh-actions/run-e2e-tests.sh "llminferenceservice and cluster_cpu" 2 "istio-gatewayapi-ext"

      - name: Check system status
        if: always()
        run: |
          ./test/scripts/gh-actions/status-check.sh

  kserve-image-build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Free-up disk space
        uses: ./.github/actions/free-up-disk-space

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build KServe images
        env:
          LLMISVC_CONTROLLER_IMG: ${{ env.LLMISVC_CONTROLLER_IMG }}
        run: |
          sudo mkdir -p ${DOCKER_IMAGES_PATH}
          sudo chown -R $USER ${DOCKER_IMAGES_PATH}
          ./test/scripts/gh-actions/build-images.sh
          docker image ls
          sudo ls -lh ${DOCKER_IMAGES_PATH}

      - name: Upload controller image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.CONTROLLER_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.CONTROLLER_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error

      - name: Upload LLM controller image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.LLMISVC_CONTROLLER_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.LLMISVC_CONTROLLER_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error

      - name: Upload localmodel controller image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.LOCALMODEL_CONTROLLER_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.LOCALMODEL_CONTROLLER_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error

      - name: Upload localmodel agent image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.LOCALMODEL_AGENT_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.LOCALMODEL_AGENT_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error

      - name: Upload agent image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.AGENT_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.AGENT_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error

      - name: Upload storage initializer image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.STORAGE_INIT_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.STORAGE_INIT_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error

      - name: Upload router image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.ROUTER_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.ROUTER_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error
