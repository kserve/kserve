name: LLMInferenceService E2E Tests

on:
  pull_request:
    branches: [master, release*, feature-llmd-*]
    paths:
      - "**"
      - "!.github/**"
      - "!docs/**"
      - "!**.md"
      - ".github/workflows/e2e-test-llmisvc.yml"
  workflow_dispatch:

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  DOCKER_IMAGES_PATH: "/mnt/docker-images"
  DOCKER_REPO: "kserve"
  BASE_ARTIFACT_PREFIX: "base"
  # LLM test images
  LLMISVC_CONTROLLER_IMG: "llmisvc-controller"
  STORAGE_INIT_IMG: "storage-initializer"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test-llmisvc:
    runs-on: ubuntu-22.04
    needs: [kserve-image-build]
    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Free-up disk space
        uses: ./.github/actions/free-up-disk-space

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Setup Minikube
        uses: ./.github/actions/minikube-setup
        with:
          addons: "metallb"

      - name: KServe dependency setup
        uses: ./.github/actions/kserve-dep-setup
        with:
          network-layer: "istio-gatewayapi-ext"
          enable-lws: "true"

      - name: Download LLM images
        uses: actions/download-artifact@v4
        with:
          path: ./tmp
          pattern: ${{ env.BASE_ARTIFACT_PREFIX }}-*
          merge-multiple: true

      - name: Load LLM images
        run: |
          files=$(find ./tmp -maxdepth 1 -type f)
          for file in ${files[@]};do
            echo "Loading image $(basename ${file})"
            docker image load -i ${file}
          done
          rm -rf ./tmp
          docker image ls

      - name: Setup UV
        run: ./test/scripts/gh-actions/setup-uv.sh

      - name: Install KServe (minimal for LLM)
        run: |
          # Install CRDs, ConfigMap, and test infrastructure
          echo "üèóÔ∏è Installing minimal KServe components for LLM tests..."

          # Install CRDs
          kubectl apply --server-side=true --force-conflicts -k config/crd
          kubectl wait --for=condition=established --timeout=60s crd/llminferenceserviceconfigs.serving.kserve.io

          # Install ConfigMap, RBAC, cert-manager, webhooks, and LLM presets (without main controller)
          kubectl apply --server-side=true -k config/configmap
          kubectl apply --server-side=true -k config/rbac
          kubectl apply --server-side=true -k config/certmanager
          kubectl apply --server-side=true -k config/webhook
          kubectl apply --server-side=true -k config/llmisvc
          kubectl apply --server-side=true -k config/overlays/test/minio

          # Wait for certificate to be ready
          kubectl wait --for=condition=Ready certificate/serving-cert -n kserve --timeout=60s

          # Create namespace and test secrets
          kubectl create namespace kserve-ci-e2e-test
          kubectl apply -f config/overlays/test/minio/minio-user-secret.yaml -n kserve-ci-e2e-test

          # Wait for MinIO to be ready
          kubectl wait --for=condition=Ready pods -l app=minio -n kserve --timeout=180s

          # Initialize test models in MinIO
          kubectl apply -f config/overlays/test/minio/minio-init-job.yaml -n kserve
          kubectl wait --for=condition=complete --timeout=90s job/minio-init -n kserve

          echo "‚úÖ Minimal KServe installation complete!"

      - name: Setup LLM Controller
        run: |
          # Deploy the dedicated LLM controller
          echo "üöÄ Setting up dedicated LLM controller..."

          # Apply LLM controller RBAC
          kubectl apply -f config/rbac/llmisvc/role.yaml
          kubectl create clusterrolebinding llmisvc-manager-rolebinding \
            --clusterrole=llmisvc-manager-role \
            --serviceaccount=kserve:kserve-controller-manager \
            --dry-run=client -o yaml | kubectl apply -f -

          # Create LLM controller deployment
          kubectl apply -f - <<EOF
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            labels:
              app.kubernetes.io/name: llm-isvc-controller-manager
              control-plane: llm-isvc-controller-manager
            name: llm-isvc-controller-manager
            namespace: kserve
          spec:
            replicas: 1
            selector:
              matchLabels:
                control-plane: llm-isvc-controller-manager
            template:
              metadata:
                annotations:
                  kubectl.kubernetes.io/default-container: manager
                labels:
                  control-plane: llm-isvc-controller-manager
              spec:
                containers:
                - args:
                  - --metrics-addr=127.0.0.1:8080
                  - --leader-elect
                  env:
                  - name: POD_NAMESPACE
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.namespace
                  image: ${{ env.DOCKER_REPO }}/${{ env.LLMISVC_CONTROLLER_IMG }}:${{ github.sha }}
                  name: manager
                  ports:
                  - containerPort: 9443
                    name: webhook-server
                    protocol: TCP
                  resources:
                    limits:
                      cpu: 500m
                      memory: 128Mi
                    requests:
                      cpu: 10m
                      memory: 64Mi
                  securityContext:
                    allowPrivilegeEscalation: false
                    capabilities:
                      drop:
                      - ALL
                  volumeMounts:
                  - mountPath: /tmp/k8s-webhook-server/serving-certs
                    name: cert
                    readOnly: true
                securityContext:
                  runAsNonRoot: true
                serviceAccountName: kserve-controller-manager
                terminationGracePeriodSeconds: 10
                volumes:
                - name: cert
                  secret:
                    defaultMode: 420
                    secretName: kserve-webhook-server-cert
          EOF

          # Create LLM webhook service (using same name as certificate expects)
          kubectl apply -f - <<EOF
          apiVersion: v1
          kind: Service
          metadata:
            name: kserve-webhook-server-service
            namespace: kserve
          spec:
            ports:
            - name: webhook-server
              port: 443
              targetPort: 9443
            selector:
              control-plane: llm-isvc-controller-manager
          EOF

          echo "‚úÖ LLM controller setup complete!"

      - name: Run E2E tests
        timeout-minutes: 30
        run: |
          # Run only CPU tests for now using pytest markers (cluster_)
          # Available GPU vendors: amd, nvidia, intel
          ./test/scripts/gh-actions/run-e2e-tests.sh "llminferenceservice and cluster_cpu" 2 "istio-gatewayapi-ext"

      - name: Check system status
        if: always()
        run: |
          ./test/scripts/gh-actions/status-check.sh

  kserve-image-build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout source
        uses: actions/checkout@v4

      - name: Free-up disk space
        uses: ./.github/actions/free-up-disk-space

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build LLM images
        run: |
          sudo mkdir -p ${DOCKER_IMAGES_PATH}
          sudo chown -R $USER ${DOCKER_IMAGES_PATH}
          ./test/scripts/gh-actions/build-llm-images.sh

          docker image ls
          sudo ls -lh ${DOCKER_IMAGES_PATH}

      - name: Upload LLM controller image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.LLMISVC_CONTROLLER_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.LLMISVC_CONTROLLER_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error

      - name: Upload storage initializer image
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BASE_ARTIFACT_PREFIX }}-${{ env.STORAGE_INIT_IMG }}-${{ github.sha }}
          path: ${{ env.DOCKER_IMAGES_PATH }}/${{ env.STORAGE_INIT_IMG }}-${{ github.sha }}
          compression-level: 0
          if-no-files-found: error
