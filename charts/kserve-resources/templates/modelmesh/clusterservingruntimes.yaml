{{- if .Values.kserve.modelmesh.enabled }}
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  labels:
    app.kubernetes.io/instance: modelmesh-controller
    app.kubernetes.io/managed-by: modelmesh-controller
    app.kubernetes.io/name: modelmesh-controller
    name: modelmesh-serving-mlserver-1.x-SR
  name: mlserver-1.x
spec:
  builtInAdapter:
    serverType: mlserver
    runtimeManagementPort: 8001
    memBufferBytes: 134217728
    modelLoadingTimeoutMillis: 90000
  containers:
    - env:
        - name: MLSERVER_MODELS_DIR
          value: /models/_mlserver_models/
        - name: MLSERVER_GRPC_PORT
          value: "8001"
        - name: MLSERVER_HTTP_PORT
          value: "8002"
        - name: MLSERVER_LOAD_MODELS_AT_STARTUP
          value: "false"
        - name: MLSERVER_MODEL_NAME
          value: dummy-model-fixme
        - name: MLSERVER_HOST
          value: 127.0.0.1
        - name: MLSERVER_GRPC_MAX_MESSAGE_LENGTH
          value: "-1"
      image: seldonio/mlserver:1.3.2
      name: mlserver
      resources:
        requests:
          cpu: 500m
          memory: 1Gi
        limits:
          cpu: "5"
          memory: 1Gi
  grpcDataEndpoint: port:8001
  grpcEndpoint: port:8085
  multiModel: true
  protocolVersions:
    - grpc-v2
  supportedModelFormats:
    - name: sklearn
      version: "0"
      autoSelect: true
    - name: xgboost
      version: "1"
      autoSelect: true
    - name: lightgbm
      version: "3"
      autoSelect: true

---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  labels:
    app.kubernetes.io/instance: modelmesh-controller
    app.kubernetes.io/managed-by: modelmesh-controller
    app.kubernetes.io/name: modelmesh-controller
    name: modelmesh-serving-ovms-1.x-SR
  name: ovms-1.x
spec:
  builtInAdapter:
    memBufferBytes: 134217728
    modelLoadingTimeoutMillis: 90000
    runtimeManagementPort: 8888
    serverType: ovms
  containers:
    - args:
        - --port=8001
        - --rest_port=8888
        - --config_path=/models/model_config_list.json
        - --file_system_poll_wait_seconds=0
        - --grpc_bind_address=127.0.0.1
        - --rest_bind_address=127.0.0.1
      image: openvino/model_server:2022.2
      name: ovms
      resources:
        limits:
          cpu: 5
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 1Gi
  grpcDataEndpoint: port:8001
  grpcEndpoint: port:8085
  multiModel: true
  protocolVersions:
    - grpc-v1
  supportedModelFormats:
    - name: openvino_ir
      version: opset1
      autoSelect: true
    - name: onnx
      version: "1"

---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  annotations:
    maxLoadingConcurrency: "2"
  labels:
    app.kubernetes.io/instance: modelmesh-controller
    app.kubernetes.io/managed-by: modelmesh-controller
    app.kubernetes.io/name: modelmesh-controller
    name: modelmesh-serving-triton-2.x-SR
  name: triton-2.x
spec:
  builtInAdapter:
    memBufferBytes: 134217728
    modelLoadingTimeoutMillis: 90000
    runtimeManagementPort: 8001
    serverType: triton
  containers:
    - command:
        - /bin/sh
      args:
        - -c
        - >
          mkdir -p /models/_triton_models;
          chmod 777 /models/_triton_models;
          exec tritonserver
          --model-repository=/models/_triton_models
          --model-control-mode=explicit
          --strict-model-config=false
          --strict-readiness=false
          --allow-http=true
          --allow-sagemaker=false
      image: nvcr.io/nvidia/tritonserver:23.04-py3
      livenessProbe:
        exec:
          command:
            - curl
            - --fail
            - --silent
            - --show-error
            - --max-time
            - "9"
            - http://localhost:8000/v2/health/live
        initialDelaySeconds: 5
        periodSeconds: 30
        timeoutSeconds: 10
      name: triton
      resources:
        limits:
          cpu: "5"
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 1Gi
  grpcDataEndpoint: port:8001
  grpcEndpoint: port:8085
  multiModel: true
  protocolVersions:
    - grpc-v2
  supportedModelFormats:
    - name: keras
      version: "2"
      autoSelect: true
    - name: onnx
      version: "1"
      autoSelect: true
    - name: pytorch
      version: "1"
      autoSelect: true
    - name: tensorflow
      version: "1"
      autoSelect: true
    - name: tensorflow
      version: "2"
      autoSelect: true
    - name: tensorrt
      version: "7"
      autoSelect: true

---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  annotations:
    maxLoadingConcurrency: "2"
  labels:
    app.kubernetes.io/instance: modelmesh-controller
    app.kubernetes.io/managed-by: modelmesh-controller
    app.kubernetes.io/name: modelmesh-controller
    name: modelmesh-serving-torchserve-0.x-SR
  name: torchserve-0.x
spec:
  supportedModelFormats:
    - name: pytorch-mar
      version: "0"
      autoSelect: true
  multiModel: true
  grpcEndpoint: "port:8085"
  grpcDataEndpoint: "port:7070"
  containers:
    - name: torchserve
      image: pytorch/torchserve:0.7.1-cpu
      args:
        # Adapter creates the config file; wait for it to exist before starting
        - while [ ! -e "$TS_CONFIG_FILE" ]; do echo "waiting for config file..."; sleep 1; done;
        - exec
        - torchserve
        - --start
        - --foreground
      env:
        - name: TS_CONFIG_FILE
          value: /models/_torchserve_models/mmconfig.properties
      resources:
        requests:
          cpu: 500m
          memory: 1Gi
        limits:
          cpu: "5"
          memory: 1Gi
  builtInAdapter:
    serverType: torchserve
    runtimeManagementPort: 7071
    memBufferBytes: 134217728
    modelLoadingTimeoutMillis: 90000
{{- end }}
