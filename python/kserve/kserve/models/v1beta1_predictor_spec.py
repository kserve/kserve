# Copyright 2023 The KServe Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# coding: utf-8

"""
    KServe

    Python SDK for KServe

    The version of the OpenAPI document: v0.1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from typing import Any, ClassVar, Dict, List, Optional
from pydantic import BaseModel, StrictBool, StrictInt, StrictStr
from pydantic import Field
from kserve.models.v1beta1_batcher import V1beta1Batcher
from kserve.models.v1beta1_light_gbm_spec import V1beta1LightGBMSpec
from kserve.models.v1beta1_logger_spec import V1beta1LoggerSpec
from kserve.models.v1beta1_model_spec import V1beta1ModelSpec
from kserve.models.v1beta1_onnx_runtime_spec import V1beta1ONNXRuntimeSpec
from kserve.models.v1beta1_paddle_server_spec import V1beta1PaddleServerSpec
from kserve.models.v1beta1_pmml_spec import V1beta1PMMLSpec
from kserve.models.v1beta1_sk_learn_spec import V1beta1SKLearnSpec
from kserve.models.v1beta1_tf_serving_spec import V1beta1TFServingSpec
from kserve.models.v1beta1_torch_serve_spec import V1beta1TorchServeSpec
from kserve.models.v1beta1_triton_spec import V1beta1TritonSpec
from kserve.models.v1beta1_xg_boost_spec import V1beta1XGBoostSpec
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class V1beta1PredictorSpec(BaseModel):
    """
    PredictorSpec defines the configuration for a predictor, The following fields follow a \"1-of\" semantic. Users must specify exactly one spec.
    """ # noqa: E501
    active_deadline_seconds: Optional[StrictInt] = Field(default=None, description="Optional duration in seconds the pod may be active on the node relative to StartTime before the system will actively try to mark it failed and kill associated containers. Value must be a positive integer.", alias="activeDeadlineSeconds")
    affinity: Optional[V1Affinity] = None
    annotations: Optional[Dict[str, StrictStr]] = Field(default=None, description="Annotations that will be add to the component pod. More info: http://kubernetes.io/docs/user-guide/annotations")
    automount_service_account_token: Optional[StrictBool] = Field(default=None, description="AutomountServiceAccountToken indicates whether a service account token should be automatically mounted.", alias="automountServiceAccountToken")
    batcher: Optional[V1beta1Batcher] = None
    canary_traffic_percent: Optional[StrictInt] = Field(default=None, description="CanaryTrafficPercent defines the traffic split percentage between the candidate revision and the last ready revision", alias="canaryTrafficPercent")
    container_concurrency: Optional[StrictInt] = Field(default=None, description="ContainerConcurrency specifies how many requests can be processed concurrently, this sets the hard limit of the container concurrency(https://knative.dev/docs/serving/autoscaling/concurrency).", alias="containerConcurrency")
    containers: Optional[List[V1Container]] = Field(default=None, description="List of containers belonging to the pod. Containers cannot currently be added or removed. There must be at least one container in a Pod. Cannot be updated.")
    dns_config: Optional[V1PodDNSConfig] = Field(default=None, alias="dnsConfig")
    dns_policy: Optional[StrictStr] = Field(default=None, description="Set DNS policy for the pod. Defaults to \"ClusterFirst\". Valid values are 'ClusterFirstWithHostNet', 'ClusterFirst', 'Default' or 'None'. DNS parameters given in DNSConfig will be merged with the policy selected with DNSPolicy. To have DNS options set along with hostNetwork, you have to specify DNS policy explicitly to 'ClusterFirstWithHostNet'.", alias="dnsPolicy")
    enable_service_links: Optional[StrictBool] = Field(default=None, description="EnableServiceLinks indicates whether information about services should be injected into pod's environment variables, matching the syntax of Docker links. Optional: Defaults to true.", alias="enableServiceLinks")
    ephemeral_containers: Optional[List[V1EphemeralContainer]] = Field(default=None, description="List of ephemeral containers run in this pod. Ephemeral containers may be run in an existing pod to perform user-initiated actions such as debugging. This list cannot be specified when creating a pod, and it cannot be modified by updating the pod spec. In order to add an ephemeral container to an existing pod, use the pod's ephemeralcontainers subresource. This field is beta-level and available on clusters that haven't disabled the EphemeralContainers feature gate.", alias="ephemeralContainers")
    host_aliases: Optional[List[V1HostAlias]] = Field(default=None, description="HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified. This is only valid for non-hostNetwork pods.", alias="hostAliases")
    host_ipc: Optional[StrictBool] = Field(default=None, description="Use the host's ipc namespace. Optional: Default to false.", alias="hostIPC")
    host_network: Optional[StrictBool] = Field(default=None, description="Host networking requested for this pod. Use the host's network namespace. If this option is set, the ports that will be used must be specified. Default to false.", alias="hostNetwork")
    host_pid: Optional[StrictBool] = Field(default=None, description="Use the host's pid namespace. Optional: Default to false.", alias="hostPID")
    host_users: Optional[StrictBool] = Field(default=None, description="Use the host's user namespace. Optional: Default to true. If set to true or not present, the pod will be run in the host user namespace, useful for when the pod needs a feature only available to the host user namespace, such as loading a kernel module with CAP_SYS_MODULE. When set to false, a new userns is created for the pod. Setting false is useful for mitigating container breakout vulnerabilities even allowing users to run their containers as root without actually having root privileges on the host. This field is alpha-level and is only honored by servers that enable the UserNamespacesSupport feature.", alias="hostUsers")
    hostname: Optional[StrictStr] = Field(default=None, description="Specifies the hostname of the Pod If not specified, the pod's hostname will be set to a system-defined value.")
    image_pull_secrets: Optional[List[V1LocalObjectReference]] = Field(default=None, description="ImagePullSecrets is an optional list of references to secrets in the same namespace to use for pulling any of the images used by this PodSpec. If specified, these secrets will be passed to individual puller implementations for them to use. For example, in the case of docker, only DockerConfig type secrets are honored. More info: https://kubernetes.io/docs/concepts/containers/images#specifying-imagepullsecrets-on-a-pod", alias="imagePullSecrets")
    init_containers: Optional[List[V1Container]] = Field(default=None, description="List of initialization containers belonging to the pod. Init containers are executed in order prior to containers being started. If any init container fails, the pod is considered to have failed and is handled according to its restartPolicy. The name for an init container or normal container must be unique among all containers. Init containers may not have Lifecycle actions, Readiness probes, Liveness probes, or Startup probes. The resourceRequirements of an init container are taken into account during scheduling by finding the highest request/limit for each resource type, and then using the max of of that value or the sum of the normal containers. Limits are applied to init containers in a similar fashion. Init containers cannot currently be added or removed. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/", alias="initContainers")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="Labels that will be add to the component pod. More info: http://kubernetes.io/docs/user-guide/labels")
    lightgbm: Optional[V1beta1LightGBMSpec] = None
    logger: Optional[V1beta1LoggerSpec] = None
    max_replicas: Optional[StrictInt] = Field(default=None, description="Maximum number of replicas for autoscaling.", alias="maxReplicas")
    min_replicas: Optional[StrictInt] = Field(default=None, description="Minimum number of replicas, defaults to 1 but can be set to 0 to enable scale-to-zero.", alias="minReplicas")
    model: Optional[V1beta1ModelSpec] = None
    node_name: Optional[StrictStr] = Field(default=None, description="NodeName is a request to schedule this pod onto a specific node. If it is non-empty, the scheduler simply schedules this pod onto that node, assuming that it fits resource requirements.", alias="nodeName")
    node_selector: Optional[Dict[str, StrictStr]] = Field(default=None, description="NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/", alias="nodeSelector")
    onnx: Optional[V1beta1ONNXRuntimeSpec] = None
    os: Optional[V1PodOS] = None
    overhead: Optional[Dict[str, ResourceQuantity]] = Field(default=None, description="Overhead represents the resource overhead associated with running a pod for a given RuntimeClass. This field will be autopopulated at admission time by the RuntimeClass admission controller. If the RuntimeClass admission controller is enabled, overhead must not be set in Pod create requests. The RuntimeClass admission controller will reject Pod create requests which have the overhead already set. If RuntimeClass is configured and selected in the PodSpec, Overhead will be set to the value defined in the corresponding RuntimeClass, otherwise it will remain unset and treated as zero. More info: https://git.k8s.io/enhancements/keps/sig-node/688-pod-overhead/README.md This field is beta-level as of Kubernetes v1.18, and is only honored by servers that enable the PodOverhead feature.")
    paddle: Optional[V1beta1PaddleServerSpec] = None
    pmml: Optional[V1beta1PMMLSpec] = None
    preemption_policy: Optional[StrictStr] = Field(default=None, description="PreemptionPolicy is the Policy for preempting pods with lower priority. One of Never, PreemptLowerPriority. Defaults to PreemptLowerPriority if unset. This field is beta-level, gated by the NonPreemptingPriority feature-gate.", alias="preemptionPolicy")
    priority: Optional[StrictInt] = Field(default=None, description="The priority value. Various system components use this field to find the priority of the pod. When Priority Admission Controller is enabled, it prevents users from setting this field. The admission controller populates this field from PriorityClassName. The higher the value, the higher the priority.")
    priority_class_name: Optional[StrictStr] = Field(default=None, description="If specified, indicates the pod's priority. \"system-node-critical\" and \"system-cluster-critical\" are two special keywords which indicate the highest priorities with the former being the highest priority. Any other name must be defined by creating a PriorityClass object with that name. If not specified, the pod priority will be default or zero if there is no default.", alias="priorityClassName")
    pytorch: Optional[V1beta1TorchServeSpec] = None
    readiness_gates: Optional[List[V1PodReadinessGate]] = Field(default=None, description="If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://git.k8s.io/enhancements/keps/sig-network/580-pod-readiness-gates", alias="readinessGates")
    resource_claims: Optional[List[V1PodResourceClaim]] = Field(default=None, description="ResourceClaims defines which ResourceClaims must be allocated and reserved before the Pod is allowed to start. The resources will be made available to those containers which consume them by name.  This is an alpha field and requires enabling the DynamicResourceAllocation feature gate.  This field is immutable.", alias="resourceClaims")
    restart_policy: Optional[StrictStr] = Field(default=None, description="Restart policy for all containers within the pod. One of Always, OnFailure, Never. Default to Always. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy", alias="restartPolicy")
    runtime_class_name: Optional[StrictStr] = Field(default=None, description="RuntimeClassName refers to a RuntimeClass object in the node.k8s.io group, which should be used to run this pod.  If no RuntimeClass resource matches the named class, the pod will not be run. If unset or empty, the \"legacy\" RuntimeClass will be used, which is an implicit class with an empty definition that uses the default runtime handler. More info: https://git.k8s.io/enhancements/keps/sig-node/585-runtime-class This is a beta feature as of Kubernetes v1.14.", alias="runtimeClassName")
    scale_metric: Optional[StrictStr] = Field(default=None, description="ScaleMetric defines the scaling metric type watched by autoscaler possible values are concurrency, rps, cpu, memory. concurrency, rps are supported via Knative Pod Autoscaler(https://knative.dev/docs/serving/autoscaling/autoscaling-metrics).", alias="scaleMetric")
    scale_target: Optional[StrictInt] = Field(default=None, description="ScaleTarget specifies the integer target value of the metric type the Autoscaler watches for. concurrency and rps targets are supported by Knative Pod Autoscaler (https://knative.dev/docs/serving/autoscaling/autoscaling-targets/).", alias="scaleTarget")
    scheduler_name: Optional[StrictStr] = Field(default=None, description="If specified, the pod will be dispatched by specified scheduler. If not specified, the pod will be dispatched by default scheduler.", alias="schedulerName")
    scheduling_gates: Optional[List[V1PodSchedulingGate]] = Field(default=None, description="SchedulingGates is an opaque list of values that if specified will block scheduling the pod. If schedulingGates is not empty, the pod will stay in the SchedulingGated state and the scheduler will not attempt to schedule the pod.  SchedulingGates can only be set at pod creation time, and be removed only afterwards.  This is a beta feature enabled by the PodSchedulingReadiness feature gate.", alias="schedulingGates")
    security_context: Optional[V1PodSecurityContext] = Field(default=None, alias="securityContext")
    service_account: Optional[StrictStr] = Field(default=None, description="DeprecatedServiceAccount is a depreciated alias for ServiceAccountName. Deprecated: Use serviceAccountName instead.", alias="serviceAccount")
    service_account_name: Optional[StrictStr] = Field(default=None, description="ServiceAccountName is the name of the ServiceAccount to use to run this pod. More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/", alias="serviceAccountName")
    set_hostname_as_fqdn: Optional[StrictBool] = Field(default=None, description="If true the pod's hostname will be configured as the pod's FQDN, rather than the leaf name (the default). In Linux containers, this means setting the FQDN in the hostname field of the kernel (the nodename field of struct utsname). In Windows containers, this means setting the registry value of hostname for the registry key HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters to FQDN. If a pod does not have FQDN, this has no effect. Default to false.", alias="setHostnameAsFQDN")
    share_process_namespace: Optional[StrictBool] = Field(default=None, description="Share a single process namespace between all of the containers in a pod. When this is set containers will be able to view and signal processes from other containers in the same pod, and the first process in each container will not be assigned PID 1. HostPID and ShareProcessNamespace cannot both be set. Optional: Default to false.", alias="shareProcessNamespace")
    sklearn: Optional[V1beta1SKLearnSpec] = None
    subdomain: Optional[StrictStr] = Field(default=None, description="If specified, the fully qualified Pod hostname will be \"<hostname>.<subdomain>.<pod namespace>.svc.<cluster domain>\". If not specified, the pod will not have a domainname at all.")
    tensorflow: Optional[V1beta1TFServingSpec] = None
    termination_grace_period_seconds: Optional[StrictInt] = Field(default=None, description="Optional duration in seconds the pod needs to terminate gracefully. May be decreased in delete request. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). If this value is nil, the default grace period will be used instead. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. Defaults to 30 seconds.", alias="terminationGracePeriodSeconds")
    timeout: Optional[StrictInt] = Field(default=None, description="TimeoutSeconds specifies the number of seconds to wait before timing out a request to the component.")
    tolerations: Optional[List[V1Toleration]] = Field(default=None, description="If specified, the pod's tolerations.")
    topology_spread_constraints: Optional[List[V1TopologySpreadConstraint]] = Field(default=None, description="TopologySpreadConstraints describes how a group of pods ought to spread across topology domains. Scheduler will schedule pods in a way which abides by the constraints. All topologySpreadConstraints are ANDed.", alias="topologySpreadConstraints")
    triton: Optional[V1beta1TritonSpec] = None
    volumes: Optional[List[V1Volume]] = Field(default=None, description="List of volumes that can be mounted by containers belonging to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes")
    xgboost: Optional[V1beta1XGBoostSpec] = None
    __properties: ClassVar[List[str]] = ["activeDeadlineSeconds", "affinity", "annotations", "automountServiceAccountToken", "batcher", "canaryTrafficPercent", "containerConcurrency", "containers", "dnsConfig", "dnsPolicy", "enableServiceLinks", "ephemeralContainers", "hostAliases", "hostIPC", "hostNetwork", "hostPID", "hostUsers", "hostname", "imagePullSecrets", "initContainers", "labels", "lightgbm", "logger", "maxReplicas", "minReplicas", "model", "nodeName", "nodeSelector", "onnx", "os", "overhead", "paddle", "pmml", "preemptionPolicy", "priority", "priorityClassName", "pytorch", "readinessGates", "resourceClaims", "restartPolicy", "runtimeClassName", "scaleMetric", "scaleTarget", "schedulerName", "schedulingGates", "securityContext", "serviceAccount", "serviceAccountName", "setHostnameAsFQDN", "shareProcessNamespace", "sklearn", "subdomain", "tensorflow", "terminationGracePeriodSeconds", "timeout", "tolerations", "topologySpreadConstraints", "triton", "volumes", "xgboost"]

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of V1beta1PredictorSpec from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of affinity
        if self.affinity:
            _dict['affinity'] = self.affinity.to_dict()
        # override the default output from pydantic by calling `to_dict()` of batcher
        if self.batcher:
            _dict['batcher'] = self.batcher.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in containers (list)
        _items = []
        if self.containers:
            for _item in self.containers:
                if _item:
                    _items.append(_item.to_dict())
            _dict['containers'] = _items
        # override the default output from pydantic by calling `to_dict()` of dns_config
        if self.dns_config:
            _dict['dnsConfig'] = self.dns_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in ephemeral_containers (list)
        _items = []
        if self.ephemeral_containers:
            for _item in self.ephemeral_containers:
                if _item:
                    _items.append(_item.to_dict())
            _dict['ephemeralContainers'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in host_aliases (list)
        _items = []
        if self.host_aliases:
            for _item in self.host_aliases:
                if _item:
                    _items.append(_item.to_dict())
            _dict['hostAliases'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in image_pull_secrets (list)
        _items = []
        if self.image_pull_secrets:
            for _item in self.image_pull_secrets:
                if _item:
                    _items.append(_item.to_dict())
            _dict['imagePullSecrets'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in init_containers (list)
        _items = []
        if self.init_containers:
            for _item in self.init_containers:
                if _item:
                    _items.append(_item.to_dict())
            _dict['initContainers'] = _items
        # override the default output from pydantic by calling `to_dict()` of lightgbm
        if self.lightgbm:
            _dict['lightgbm'] = self.lightgbm.to_dict()
        # override the default output from pydantic by calling `to_dict()` of logger
        if self.logger:
            _dict['logger'] = self.logger.to_dict()
        # override the default output from pydantic by calling `to_dict()` of model
        if self.model:
            _dict['model'] = self.model.to_dict()
        # override the default output from pydantic by calling `to_dict()` of onnx
        if self.onnx:
            _dict['onnx'] = self.onnx.to_dict()
        # override the default output from pydantic by calling `to_dict()` of os
        if self.os:
            _dict['os'] = self.os.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each value in overhead (dict)
        _field_dict = {}
        if self.overhead:
            for _key in self.overhead:
                if self.overhead[_key]:
                    _field_dict[_key] = self.overhead[_key].to_dict()
            _dict['overhead'] = _field_dict
        # override the default output from pydantic by calling `to_dict()` of paddle
        if self.paddle:
            _dict['paddle'] = self.paddle.to_dict()
        # override the default output from pydantic by calling `to_dict()` of pmml
        if self.pmml:
            _dict['pmml'] = self.pmml.to_dict()
        # override the default output from pydantic by calling `to_dict()` of pytorch
        if self.pytorch:
            _dict['pytorch'] = self.pytorch.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in readiness_gates (list)
        _items = []
        if self.readiness_gates:
            for _item in self.readiness_gates:
                if _item:
                    _items.append(_item.to_dict())
            _dict['readinessGates'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in resource_claims (list)
        _items = []
        if self.resource_claims:
            for _item in self.resource_claims:
                if _item:
                    _items.append(_item.to_dict())
            _dict['resourceClaims'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in scheduling_gates (list)
        _items = []
        if self.scheduling_gates:
            for _item in self.scheduling_gates:
                if _item:
                    _items.append(_item.to_dict())
            _dict['schedulingGates'] = _items
        # override the default output from pydantic by calling `to_dict()` of security_context
        if self.security_context:
            _dict['securityContext'] = self.security_context.to_dict()
        # override the default output from pydantic by calling `to_dict()` of sklearn
        if self.sklearn:
            _dict['sklearn'] = self.sklearn.to_dict()
        # override the default output from pydantic by calling `to_dict()` of tensorflow
        if self.tensorflow:
            _dict['tensorflow'] = self.tensorflow.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in tolerations (list)
        _items = []
        if self.tolerations:
            for _item in self.tolerations:
                if _item:
                    _items.append(_item.to_dict())
            _dict['tolerations'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in topology_spread_constraints (list)
        _items = []
        if self.topology_spread_constraints:
            for _item in self.topology_spread_constraints:
                if _item:
                    _items.append(_item.to_dict())
            _dict['topologySpreadConstraints'] = _items
        # override the default output from pydantic by calling `to_dict()` of triton
        if self.triton:
            _dict['triton'] = self.triton.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in volumes (list)
        _items = []
        if self.volumes:
            for _item in self.volumes:
                if _item:
                    _items.append(_item.to_dict())
            _dict['volumes'] = _items
        # override the default output from pydantic by calling `to_dict()` of xgboost
        if self.xgboost:
            _dict['xgboost'] = self.xgboost.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of V1beta1PredictorSpec from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "activeDeadlineSeconds": obj.get("activeDeadlineSeconds"),
            "affinity": V1Affinity.from_dict(obj.get("affinity")) if obj.get("affinity") is not None else None,
            "annotations": obj.get("annotations"),
            "automountServiceAccountToken": obj.get("automountServiceAccountToken"),
            "batcher": V1beta1Batcher.from_dict(obj.get("batcher")) if obj.get("batcher") is not None else None,
            "canaryTrafficPercent": obj.get("canaryTrafficPercent"),
            "containerConcurrency": obj.get("containerConcurrency"),
            "containers": [V1Container.from_dict(_item) for _item in obj.get("containers")] if obj.get("containers") is not None else None,
            "dnsConfig": V1PodDNSConfig.from_dict(obj.get("dnsConfig")) if obj.get("dnsConfig") is not None else None,
            "dnsPolicy": obj.get("dnsPolicy"),
            "enableServiceLinks": obj.get("enableServiceLinks"),
            "ephemeralContainers": [V1EphemeralContainer.from_dict(_item) for _item in obj.get("ephemeralContainers")] if obj.get("ephemeralContainers") is not None else None,
            "hostAliases": [V1HostAlias.from_dict(_item) for _item in obj.get("hostAliases")] if obj.get("hostAliases") is not None else None,
            "hostIPC": obj.get("hostIPC"),
            "hostNetwork": obj.get("hostNetwork"),
            "hostPID": obj.get("hostPID"),
            "hostUsers": obj.get("hostUsers"),
            "hostname": obj.get("hostname"),
            "imagePullSecrets": [V1LocalObjectReference.from_dict(_item) for _item in obj.get("imagePullSecrets")] if obj.get("imagePullSecrets") is not None else None,
            "initContainers": [V1Container.from_dict(_item) for _item in obj.get("initContainers")] if obj.get("initContainers") is not None else None,
            "labels": obj.get("labels"),
            "lightgbm": V1beta1LightGBMSpec.from_dict(obj.get("lightgbm")) if obj.get("lightgbm") is not None else None,
            "logger": V1beta1LoggerSpec.from_dict(obj.get("logger")) if obj.get("logger") is not None else None,
            "maxReplicas": obj.get("maxReplicas"),
            "minReplicas": obj.get("minReplicas"),
            "model": V1beta1ModelSpec.from_dict(obj.get("model")) if obj.get("model") is not None else None,
            "nodeName": obj.get("nodeName"),
            "nodeSelector": obj.get("nodeSelector"),
            "onnx": V1beta1ONNXRuntimeSpec.from_dict(obj.get("onnx")) if obj.get("onnx") is not None else None,
            "os": V1PodOS.from_dict(obj.get("os")) if obj.get("os") is not None else None,
            "overhead": dict(
                (_k, ResourceQuantity.from_dict(_v))
                for _k, _v in obj.get("overhead").items()
            )
            if obj.get("overhead") is not None
            else None,
            "paddle": V1beta1PaddleServerSpec.from_dict(obj.get("paddle")) if obj.get("paddle") is not None else None,
            "pmml": V1beta1PMMLSpec.from_dict(obj.get("pmml")) if obj.get("pmml") is not None else None,
            "preemptionPolicy": obj.get("preemptionPolicy"),
            "priority": obj.get("priority"),
            "priorityClassName": obj.get("priorityClassName"),
            "pytorch": V1beta1TorchServeSpec.from_dict(obj.get("pytorch")) if obj.get("pytorch") is not None else None,
            "readinessGates": [V1PodReadinessGate.from_dict(_item) for _item in obj.get("readinessGates")] if obj.get("readinessGates") is not None else None,
            "resourceClaims": [V1PodResourceClaim.from_dict(_item) for _item in obj.get("resourceClaims")] if obj.get("resourceClaims") is not None else None,
            "restartPolicy": obj.get("restartPolicy"),
            "runtimeClassName": obj.get("runtimeClassName"),
            "scaleMetric": obj.get("scaleMetric"),
            "scaleTarget": obj.get("scaleTarget"),
            "schedulerName": obj.get("schedulerName"),
            "schedulingGates": [V1PodSchedulingGate.from_dict(_item) for _item in obj.get("schedulingGates")] if obj.get("schedulingGates") is not None else None,
            "securityContext": V1PodSecurityContext.from_dict(obj.get("securityContext")) if obj.get("securityContext") is not None else None,
            "serviceAccount": obj.get("serviceAccount"),
            "serviceAccountName": obj.get("serviceAccountName"),
            "setHostnameAsFQDN": obj.get("setHostnameAsFQDN"),
            "shareProcessNamespace": obj.get("shareProcessNamespace"),
            "sklearn": V1beta1SKLearnSpec.from_dict(obj.get("sklearn")) if obj.get("sklearn") is not None else None,
            "subdomain": obj.get("subdomain"),
            "tensorflow": V1beta1TFServingSpec.from_dict(obj.get("tensorflow")) if obj.get("tensorflow") is not None else None,
            "terminationGracePeriodSeconds": obj.get("terminationGracePeriodSeconds"),
            "timeout": obj.get("timeout"),
            "tolerations": [V1Toleration.from_dict(_item) for _item in obj.get("tolerations")] if obj.get("tolerations") is not None else None,
            "topologySpreadConstraints": [V1TopologySpreadConstraint.from_dict(_item) for _item in obj.get("topologySpreadConstraints")] if obj.get("topologySpreadConstraints") is not None else None,
            "triton": V1beta1TritonSpec.from_dict(obj.get("triton")) if obj.get("triton") is not None else None,
            "volumes": [V1Volume.from_dict(_item) for _item in obj.get("volumes")] if obj.get("volumes") is not None else None,
            "xgboost": V1beta1XGBoostSpec.from_dict(obj.get("xgboost")) if obj.get("xgboost") is not None else None
        })
        return _obj


