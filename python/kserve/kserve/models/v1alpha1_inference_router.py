# Copyright 2023 The KServe Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# coding: utf-8

"""
    KServe

    Python SDK for KServe

    The version of the OpenAPI document: v0.1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from typing import Any, ClassVar, Dict, List, Optional
from pydantic import BaseModel, StrictStr
from pydantic import Field
from kserve.models.v1alpha1_inference_step import V1alpha1InferenceStep
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class V1alpha1InferenceRouter(BaseModel):
    """
    InferenceRouter defines the router for each InferenceGraph node with one or multiple steps  ```yaml kind: InferenceGraph metadata:   name: canary-route  spec:   nodes:    root:      routerType: Splitter      routes:      - service: mymodel1        weight: 20      - service: mymodel2        weight: 80  ```  ```yaml kind: InferenceGraph metadata:   name: abtest  spec:   nodes:    mymodel:      routerType: Switch      routes:      - service: mymodel1        condition: \"{ .input.userId == 1 }\"      - service: mymodel2        condition: \"{ .input.userId == 2 }\"  ```  Scoring a case using a model ensemble consists of scoring it using each model separately, then combining the results into a single scoring result using one of the pre-defined combination methods.  Tree Ensemble constitutes a case where simple algorithms for combining results of either classification or regression trees are well known. Multiple classification trees, for example, are commonly combined using a \"majority-vote\" method. Multiple regression trees are often combined using various averaging techniques. e.g tagging models with segment identifiers and weights to be used for their combination in these ways. ```yaml kind: InferenceGraph metadata:   name: ensemble  spec:   nodes:    root:      routerType: Sequence      routes:      - service: feast      - nodeName: ensembleModel        data: $response    ensembleModel:      routerType: Ensemble      routes:      - service: sklearn-model      - service: xgboost-model  ```  Scoring a case using a sequence, or chain of models allows the output of one model to be passed in as input to the subsequent models. ```yaml kind: InferenceGraph metadata:   name: model-chainer  spec:   nodes:    root:      routerType: Sequence      routes:      - service: mymodel-s1      - service: mymodel-s2        data: $response      - service: mymodel-s3        data: $response  ```  In the flow described below, the pre_processing node base64 encodes the image and passes it to two model nodes in the flow. The encoded data is available to both these nodes for classification. The second node i.e. dog-breed-classification takes the original input from the pre_processing node along-with the response from the cat-dog-classification node to do further classification of the dog breed if required. ```yaml kind: InferenceGraph metadata:   name: dog-breed-classification  spec:   nodes:    root:      routerType: Sequence      routes:      - service: cat-dog-classifier      - nodeName: breed-classifier        data: $request    breed-classifier:      routerType: Switch      routes:      - service: dog-breed-classifier        condition: { .predictions.class == \"dog\" }      - service: cat-breed-classifier        condition: { .predictions.class == \"cat\" }  ```
    """ # noqa: E501
    router_type: StrictStr = Field(description="RouterType  - `Sequence:` chain multiple inference steps with input/output from previous step  - `Splitter:` randomly routes to the target service according to the weight  - `Ensemble:` routes the request to multiple models and then merge the responses  - `Switch:` routes the request to one of the steps based on condition", alias="routerType")
    steps: Optional[List[V1alpha1InferenceStep]] = Field(default=None, description="Steps defines destinations for the current router node")
    __properties: ClassVar[List[str]] = ["routerType", "steps"]

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of V1alpha1InferenceRouter from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in steps (list)
        _items = []
        if self.steps:
            for _item in self.steps:
                if _item:
                    _items.append(_item.to_dict())
            _dict['steps'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of V1alpha1InferenceRouter from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "routerType": obj.get("routerType") if obj.get("routerType") is not None else '',
            "steps": [V1alpha1InferenceStep.from_dict(_item) for _item in obj.get("steps")] if obj.get("steps") is not None else None
        })
        return _obj


